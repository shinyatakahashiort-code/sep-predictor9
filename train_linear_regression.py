"""ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨ä¿å­˜"""
import pandas as pd
import numpy as np
import joblib
import json
from pathlib import Path
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_validate, RepeatedKFold
from sklearn.preprocessing import StandardScaler

def train_and_save_linear_regression(data_file='training_data.csv'):
    """
    ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ä¿å­˜
    
    Parameters:
    -----------
    data_file : str
        å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    
    # ãƒ‘ã‚¹ã®è¨­å®š
    MODEL_DIR = Path('saved_models')
    MODEL_DIR.mkdir(exist_ok=True)
    
    print("=" * 60)
    print("ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    print(f"\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™: {data_file}")
    try:
        df = pd.read_csv(data_file)
        print(f"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    except FileNotFoundError:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {data_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  train_and_save_linear_regression('your_data.csv')")
        return
    
    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®è¨­å®š
    feature_columns = ['å¹´é½¢', 'æ€§åˆ¥', 'Kï¼ˆAVGï¼‰', 'AL', 'LT', 'ACD']
    target_column = 'SE_p'
    
    # åˆ—åã®ç¢ºèª
    missing_cols = [col for col in feature_columns + [target_column] if col not in df.columns]
    if missing_cols:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ä»¥ä¸‹ã®åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_cols}")
        print(f"åˆ©ç”¨å¯èƒ½ãªåˆ—: {df.columns.tolist()}")
        return
    
    X = df[feature_columns]
    y = df[target_column]
    
    print(f"\nğŸ“Š ç‰¹å¾´é‡: {feature_columns}")
    print(f"ğŸ“Š ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {target_column}")
    
    # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ä½œæˆã¨é©ç”¨
    print("\nâš™ï¸ ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ã‚’å®Ÿè¡Œä¸­...")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
    print("ğŸ”§ ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
    model = LinearRegression()
    model.fit(X_scaled, y)
    
    # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®æ€§èƒ½è©•ä¾¡
    print("ğŸ“ˆ ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§æ€§èƒ½ã‚’è©•ä¾¡ä¸­...")
    cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)
    
    scoring = {
        'r2': 'r2',
        'neg_mse': 'neg_mean_squared_error',
        'neg_mae': 'neg_mean_absolute_error'
    }
    
    cv_results = cross_validate(
        model, X_scaled, y,
        cv=cv,
        scoring=scoring,
        return_train_score=False,
        n_jobs=-1
    )
    
    # æ€§èƒ½æŒ‡æ¨™ã®è¨ˆç®—
    r2_scores = cv_results['test_r2']
    mse_scores = -cv_results['test_neg_mse']
    mae_scores = -cv_results['test_neg_mae']
    rmse_scores = np.sqrt(mse_scores)
    
    r2_mean = float(np.mean(r2_scores))
    r2_std = float(np.std(r2_scores))
    rmse_mean = float(np.mean(rmse_scores))
    rmse_std = float(np.std(rmse_scores))
    mae_mean = float(np.mean(mae_scores))
    mae_std = float(np.std(mae_scores))
    
    print("\n" + "=" * 60)
    print("ğŸ“Š ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½")
    print("=" * 60)
    print(f"RÂ² Score: {r2_mean:.4f} Â± {r2_std:.4f}")
    print(f"RMSE:     {rmse_mean:.4f} Â± {rmse_std:.4f}")
    print(f"MAE:      {mae_mean:.4f} Â± {mae_std:.4f}")
    
    # ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ä¿å­˜
    print("\nğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¦ã„ã¾ã™...")
    joblib.dump(model, MODEL_DIR / 'LinearRegression.pkl')
    joblib.dump(scaler, MODEL_DIR / 'LinearRegression_scaler.pkl')
    
    # metadata.jsonã®æ›´æ–°
    metadata_path = MODEL_DIR / 'metadata.json'
    
    try:
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
    except FileNotFoundError:
        print("âš ï¸ metadata.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
        metadata = {
            'feature_columns': feature_columns,
            'models': {}
        }
    
    # ç·šå½¢å›å¸°ã®æƒ…å ±ã‚’è¿½åŠ 
    metadata['models']['LinearRegression'] = {
        'model_file': 'LinearRegression.pkl',
        'scaler_file': 'LinearRegression_scaler.pkl',
        'needs_scaling': True,
        'performance': {
            'outer_r2_mean': r2_mean,
            'outer_r2_std': r2_std,
            'outer_rmse_mean': rmse_mean,
            'outer_rmse_std': rmse_std,
            'outer_mae_mean': mae_mean,
            'outer_mae_std': mae_std
        },
        'description': 'ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆè§£é‡ˆæ€§ãŒé«˜ã„ï¼‰'
    }
    
    # metadata.jsonã‚’ä¿å­˜
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    print("\nâœ… ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print(f"\nä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"  ğŸ“„ {MODEL_DIR / 'LinearRegression.pkl'}")
    print(f"  ğŸ“„ {MODEL_DIR / 'LinearRegression_scaler.pkl'}")
    print(f"  ğŸ“„ {metadata_path} (æ›´æ–°)")
    
    # ä¿‚æ•°ã®è¡¨ç¤º
    print("\n" + "=" * 60)
    print("ğŸ” ç·šå½¢å›å¸°ã®ä¿‚æ•°")
    print("=" * 60)
    for feature, coef in zip(feature_columns, model.coef_):
        print(f"  {feature:12s}: {coef:>8.4f}")
    print(f"  {'åˆ‡ç‰‡':12s}: {model.intercept_:>8.4f}")
    print("=" * 60)


if __name__ == "__main__":
    # ä½¿ç”¨ä¾‹
    import sys
    
    if len(sys.argv) > 1:
        data_file = sys.argv[1]
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«å
        data_file = 'training_data.csv'
        print(f"ä½¿ç”¨æ–¹æ³•: python train_linear_regression.py <ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«>")
        print(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ '{data_file}' ã‚’ä½¿ç”¨ã—ã¾ã™\n")
    
    train_and_save_linear_regression(data_file)
